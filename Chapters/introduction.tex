%!TEX root = ../tommaso-thesis.tex
%!TEX spellcheck = en_US

\chapter{Introduction}\label{ch:introduction}
% \coolchapter{Introduction}{}{ch:introduction}

Everybody uses software.
It may be the control system for a production environment of a large factory, a \emph{Customer Relationship Management} system, a social network, an application on a smartphone, or a website to book a flight.

Regardless of its use, software plays a central role in modern society: It is used in almost every human activity to automate trivial tasks and to simplify complex ones.
Its usage became massively pervasive, to the point that virtually any structured activity and process relies on software to regulate its workflow, minimize errors, and reduce costs.
Moreover, the surge of popularity of mobile computing pushed even further the momentum of this scenario, bringing the influence of software into every aspect of our lives.

As a consequence, development teams are required to write code and push new features at a sustained pace, producing changes in the codebase that cause a system to constantly change and evolve its behavior, sometimes more than once a day.
Often changes are performed by different developers, or even by different teams working on different parts of the system: Therefore, it quickly becomes impossible for a single person to have comprehension of the whole system.
It is easy to understand how a software system can gradually start to resemble an unknown black box, rather than an organized entity composed of deterministic processes.

To complicate things even further, it is often not sufficient to have a deep knowledge of the whole set of components that form a system to predict its final behavior.
Given the large number of requirements that modern software systems have to satisfy, it is usually necessary to rely on external libraries to provide the desired features.
Using external code is a good practice, as it allows for reuse and reduces the probability of a bug being present in a library used by more people.
However, these benefits come at the cost of yielding control of the system to external code, leading the consequence that, if an error arises from a library, it becomes virtually impossible to track down its origin unless by debugging the library itself.

The main focus during a development cycle is writing new code to develop new features: However, in such a complex and ever-changing scenario, a huge part of the resources put in a project are spent in maintenance and debugging~\cite{Corb1989,Fjel1983,Zelk1979,Mine2015b}.
We can break down the constituent components of maintenance in: finding and collecting problems, understanding them, locating the source of the error, and fixing the issue.
Each one of these phases comes with its own set of problems and complexities.

In such a scenario, one would imagine that the efforts for assisting developers would focus on refined tools to navigate, understand, and inspect the code.
While this is partly true, many of the modern editors and IDEs put the biggest accent on how developers write code, leaving program comprehension as a secondary task, despite it being intrinsically more complicated.


\section{Dealing With Software}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\subsubsection{The Curse of Text}
It is easy to sense why understanding software is hard: Reading code means reading text containing structured information, in a language that does not follow the same logic of natural language.
To understand a fragment of code, a developer has to mentally parse a source file, identify and extract the necessary information, and build a \emph{mental model} of the intended behavior of the software.
The same process happens when printing log messages to expose the state of the system: Log messages embody fragments of information that the developer has to fit into her mental model, and use it to reverse engineer the source of an error by trial and error.

To ease this process, both researchers and industry practitioners built a plethora of tools, like debuggers and code inspectors, to allow developers run a program in a controlled environment while checking the internal status of its variables.
Other tools, like code browsers, support fast linking between the entities in the code, while loggers allow to print and store useful runtime information.
Finally, test suites allow to define a set of expected behaviors, and to constantly check if any of these rules are satisfied.

All these tools however do not change the fundamental way we interact with the code: Eventually, the developer needs to read the code, and therefore undergo the process of building its mental model.
The main cause for this is because all these tools rely on the same, strong, underlying assumption: Source code is text, therefore the tools we are using to interact with it are shaped around text editing tools.
This assumption reflects the way we use to store our programs, \ie plain-text files containing the declaration of our models.

%We propose a novel approach for runtime data collection: We advocate the use of objects to store information about an exception, in order to preserve the multidimensional nature of the information, and leverage the implicit properties that can be obtained by the data structure. By describing errors as first-class citizens of a system, and using a storage format that does not flatten the information, we can reify logs and leverage their expressive power to support a number of development activities. A structured data source allows to build a set of specialized tools to browse the data in an incremental fashion, to discover its implicit structure, or to enable the use of automated analysis, mitigating the need of a data cleaning phase. It can also be stored and sent for debugging purposes, thus creating bug reports with a much higher level of detail and reliability than simple plain text.

In this thesis we propose a different approach for thinking about runtime errors and software defects.
The data generated from runtime errors contains large amounts of information that is usually ignored, or stored in a textual format, that loses its original relations with the entities of the system.
We propose to promote this class of data ---such as bug reports and log files--- to full-fledged entities and store them using objects, in order to maintain the relation with the original entities living in the system.
The effect of treating entities such as bug reports or log files as first-class citizens of the development cycle, is that it enables us to deal with objects instead of plain text.
This, in turn, provides the language to turn the data into information in the correct context.
Such a tight integration enables a number of improvements to the tools we use to develop a system and creates a feedback loop with the developer that gives her a broader view on the evolution of a system.

We believe that discarding this data, usually considered as a disposable byproduct of the development process, wastes the enormous potential of an important data source.
We want to leverage the usefulness of this data and turn it into actionable information that can effectively impact the development process and reduce maintenance costs.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Thesis Statement}\label{sec:thesis}

The goal of our dissertation is to rethink how we deal we bug reports: We seek to increase the reliability of the data they contain and reduce the time required to read and understand them. We want to lay the foundations for a new generation of issue tracking systems, that leverages the power of the community and implements automated approaches to provide relevant information to developers~\cite{Zimm2010a} and alleviate the problem of noise (\ie duplicate or abandoned bug reports) inside existing issue trackers~\cite{Wang2008a}.

\filbreak

We formulate our thesis as follows:

\begin{framed}
Reifying bug reports, promoting them to first-class citizens of the development process, enables a conversation with a software system that reduces debugging time and enables automated and reliable usage analyses.
\end{framed}


We analyze existing bug repositories to understand the kind of data that is collected and how developers exploit this information to fix software defects.
We implement and test a set of exploratory tools to investigate the usage of bug reports in existing open source projects, and we design our process to collect data in a structured and reliable way.


\section{Validation}

Redesigning the concept of bug tracking is a task that encompasses a number of different subproblems.
Many of these problems come from the specifics of each development community and arise from the way developers approach their work.

Given the large number of variables in play, we feel that a canonical approach of selecting an idea, conducting a controlled experiment, and produce a conclusion would not the best approach to narrate the problem we are studying.
Instead, since we had the opportunity to propose our work to the \pha community, collect data from their day-to-day development work, and given the practical nature of the problem we considered, we decided to embrace a tool-driven approach and seek out for the feedback of developers.
We believe that conducting a full-blown evaluation process on a new issue tracking system would have been an impossible task, as its effects would begin to be observable only after years from its adoption.
Therefore we decided to present a set of exploratory studies using the fresh development data we collected, and evaluate our approaches based on the feedback from developers.


% \section{Contributions}

% We can classify the contributions presented in this dissertation under three categories:

% \subsection{Analysis}

% \begin{itemize}
  % \item We analyzed the content of existing bug repositories, for hidden properties and recurring patterns~\cite{DalS2013a,DalS2016a};

% \end{itemize}


% \subsection{Tools}

% \begin{itemize}
    % \setcounter{enumi}{2}

    % \item We built in*Bug, a tool for visually inspecting the content of existing issue trackers~\cite{DalS2013a,DalS2014a};

    % \item We built Blend, a tool that merges different data sources to visualize and navigate the evolution of a software system~\cite{DalS2015b};

    % \item We developed and deployed ShoreLine, a platform for the collection of runtime errors, and the reporting of system errors~\cite{DalS2015a};

    % \item We extended ShoreLine to allow the reified collection of runtime data and allow a better representation of the status of a system during a failure~\cite{DalS2017b}

% \end{itemize}

    % Sympathy for the Devil: Reified Collection of Runtime Errors
    %
    % How to Gamify Software Engineering
    %
    % What Makes a Satisficing Bug Report
    %
    % Blended, Not Stirred: Multiconcern visualization of large software systems
    %
    % Misery Loves Company: CrowdStacking Traces to Aid Problem Detection.
    %
    % Managing Software Defects
    %
    % in*Bug: Visual analytics of bug repositories
    %
    % A closer look at bugs (d.s.)
    %
    % Content Classification of Development Emails


% \subsection{Modeling}
%
% \begin{itemize}
%     % \setcounter{enumi}{6}
%     \item We performed a survey to investigate what users deem easy to provide in a bug report~\cite{DalS2016a};
%
%     \item We proposed a model to represent and store a bug report and the related data without losing information about its context~\cite{DalS2016a};
%
%     \item We distilled a meta-model for a minimal bug report, establishing a basic layer of core features~\cite{DalS2016a};

% \end{itemize}

\newpage
\section{Roadmap}

This dissertation is structured in the following chapters and with the following contributions:

\begin{description}
  \item[\chref{ch:related}] presents the history and evolution of tracking bugs, the current trends and best practices.

  \item[\chref{ch:visualize}] proposes a visual approach to explore the content of existing issue trackers, showing how a simple textual representation sometimes hides useful information in a bug database.
  We present \ib, a tool for visually inspecting the contents of existing bug repositories, find hidden properties, and recurring patterns.~\cite{DalS2013a,DalS2014a,DalS2014b}.

  % We presented work at VISSOFT 2013~\cite{DalS2013a} and CSMR/WCRE 2014~\cite{DalS2014a}

  % \publication{A closer look at bugs}{Tommaso Dal Sasso, Michele Lanza}{In Proceedings of VISSOFT 2013 (1st IEEE Working Conference on Software Visualization), pp. 1–4, IEEE CS Press, 2013.}{DalS2013a}

  % \publication{in*Bug: Visual analytics of bug repositories}{Tommaso Dal Sasso, Michele Lanza}{In Proceedings of CSMR-WCRE 2014 (1st Joint Meeeting of the European Conference on Software Maintenance and Reengineering and the Working Conference on Reverse Engineering), pages 415–419, IEEE CS Press, 2014.}{DalS2014a}

  % \publication{Managing Software Defects}{Tommaso Dal Sasso}{In Proceedings of ICSME 2014 (30th International Conference on Software Maintenance and Evolution, page 669, Doctoral Symposium, 2014.}{DalS2014b}


  \item[\chref{ch:stacktraces}] presents our approach for runtime errors retrieval, where we collect stack traces generated by the community during the development process to learn about the life of a system.
  We implemented our approach into ShoreLine, a platform that we deployed for the collection and reporting of runtime errors~\cite{DalS2015a}.

  % \publication{Misery Loves Company: CrowdStacking Traces to Aid Problem Detection.}{Tommaso Dal Sasso, Andrea Mocci, Michele Lanza}{In Proceedings of SANER 2015 (22nd IEEE International Conference on Software Analysis, Evolution, and Reengineering), pp. 131–140, 2015.}{DalS2015a}


  \item[\chref{ch:reified}] extends our stack traces collection approach, to log entities in a reified fashion and to capture the information implicitly stored in the relation among the objects.
  We extend ShoreLine to allow the reified collection of runtime data and allow a better representation of the status of a system during a failure~\cite{DalS2017b}

  % \publication{Sympathy for the Devil: Reified Collection of Runtime Errors}{Tommaso dal Sasso, Andrei Chis, Andrea Mocci, Tudor Girba, Michele Lanza}{In Proceedings of PLATEAU 2017 (8th International Workshop on Evaluation and Usability of Programming Languages and Tools), to be published, ACM Press, 2017}{DalS2017b}

  \item[\chref{ch:blend}] shows how we can employ the data we collect to build tools that combine heterogeneous data sources for browsing the evolution of a system from different perspectives.
  We show \blend, a tool that merges different data sources to browse the evolution of \pha~\cite{DalS2015b}.

  % \publication{Blended, Not Stirred: Multiconcern visualization of large software systems}{Tommaso Dal Sasso, Roberto Minelli, Andrea Mocci, Michele Lanza}{In Proceedings of VISSOFT 2015 (3rd IEEE Working Conference on Software Visualization), pp. 106–115 2015.}{DalS2015b}


  \item[\chref{ch:model}] discusses the general model used by issue trackers and how it falls short in helping users when they have an issue to report.
  We present a survey we performed to investigate what users deem easy to provide in a bug report.
  We distill a meta-model for a minimal bug report, establishing a basic layer of core features.
  We propose an improved model to represent and store a bug report and the related data without losing information about its context, laying the foundations for what we think will be the next generation of issue trackers.~\cite{DalS2016a}.

  % \publication{What Makes a Satisficing Bug Report}{Tommaso Dal Sasso, Andrea Mocci, Michele Lanza}{In Proceedings of QRS 2016 (The 2016 IEEE International Conference on Quality, Reliability, and Security), pp. 164–174, IEEE CS Press, 2016.}{DalS2016a}


  \item[\chref{ch:gamification}] considers the problem of the engagement of developers during a tedious activity such as reporting and fixing bugs.
  We discuss how we can improve the user experience inside an issue tracking system by employing \emph{gamification}~\cite{DalS2017a}.

  % \publication{How to Gamify Software Engineering}{Tommaso Dal Sasso, Andrea Mocci, Michele Lanza, Ebrisa Mastrodicasa}{In Proceedings of SANER 2017 (24th IEEE International Conference on Software Analysis, Evolution, and Reengineering), pp. 261–271, IEEE CS Press, 2017.}{DalS2017a}

  \item[\chref{ch:conclusion}] concludes our work by summarizing the proposed approaches and how these can show the direction for the development of integrated issue tracking systems with smarter and deeper bug reports.

  \item[\appref{ch:pharo}] presents a brief background on \pha, the main platform that we targeted to develop and test our approaches and tools.

  \item[\appref{ch:publications}] presents a list of the publications produced during our work.
\end{description}
